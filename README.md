# Crayon_X å¯»æ‰¾èœ¡ç¬”å°æ–°çš„è¿œæ–¹è¡¨å¼Ÿ

èœ¡ç¬”å°æ–°åº”è¯¥æ˜¯å¥½å¤šå°ä¼™ä¼´çš„ç«¥å¹´å›å¿†ä¹‹ä¸€ï¼Œä¸ä¼šæœ‰äººä¸å–œæ¬¢èœ¡ç¬”å°æ–°é‚£æ‹›ç‰Œçš„ç²—çœ‰æ¯›ä»¥åŠåœ†å˜Ÿå˜Ÿçš„å°è„¸è›‹å§ï¼ä¸ä¼šå§ä¸ä¼šå§ï¼ä¸‹é¢å˜ï¼Œæˆ‘ä»¬ä»¥å®¸å“¥ä½œä¸ºå·¥å…·äººï¼Œè¿˜åŸèœ¡ç¬”å°æ–°çš„è¿œæˆ¿è¡¨å¼Ÿâ€”â€”â€”â€”èœ¡ç¬”å°å®¸ï¼


## è®©æˆ‘ä»¬å…ˆçœ‹ä¸€ä¸‹èœ¡ç¬”å°å®¸ï¼Œä¸€ç¹ä¸ºå¿«ï¼

![](https://ai-studio-static-online.cdn.bcebos.com/cfa9c288b11d41e2932197ff1be6949c3938391241d649949eab3b4795443190)

è·Ÿç€æˆ‘çš„æ­¥ä¼ï¼Œå¯»æ‰¾èœ¡ç¬”å°æ–°çš„è¿œæˆ¿è¡¨å¼Ÿä¹‹è·¯ï¼Œæ­£å¼å¼€å¯ï¼(äºŒä¸‰å››æ­¥éª¤ä¸ºè¿‡ç¨‹æ¼”ç¤º~ä¸€é”®å¯»æ‰¾è¯·åœ¨**ç™»é™†èœ¡ç¬”å¤§é™†ä¹‹å**è·³è‡³ç¬¬äº”éƒ¨åˆ†)

## ä¸€ã€ç™»é™†èœ¡ç¬”å¤§é™†


```python
!pip install --upgrade pip
!pip install opencv-python==4.5.4.60
!pip install paddlehub==2.1.1
```

## äºŒã€ä½¿ç”¨PaddleHubè¿›è¡Œäººè„¸å…³é”®ç‚¹æ£€æµ‹

äººè„¸å…³é”®ç‚¹æ£€æµ‹æ˜¯äººè„¸è¯†åˆ«å’Œåˆ†æé¢†åŸŸä¸­çš„å…³é”®ä¸€æ­¥ï¼Œå®ƒæ˜¯è¯¸å¦‚è‡ªåŠ¨äººè„¸è¯†åˆ«ã€è¡¨æƒ…åˆ†æã€ä¸‰ç»´äººè„¸é‡å»ºåŠä¸‰ç»´åŠ¨ç”»ç­‰å…¶å®ƒäººè„¸ç›¸å…³é—®é¢˜çš„å‰æå’Œçªç ´å£ã€‚è¯¥ PaddleHub Module çš„æ¨¡å‹è½¬æ¢è‡ª https://github.com/lsy17096535/face-landmark ï¼Œæ”¯æŒåŒä¸€å¼ å›¾ä¸­çš„å¤šä¸ªäººè„¸æ£€æµ‹ã€‚æ­¤æ­¥çš„ç›®çš„æ˜¯è·å–äººè„¸68ä¸ªå…³é”®ç‚¹çš„åæ ‡ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚æœ‰äº†äººè„¸68ä¸ªå…³é”®ç‚¹çš„åæ ‡ï¼Œå†æ¥ä¸‹æ¥è¿›è¡Œèœ¡ç¬”çœ‰çš„åˆ»ç”»ï¼Œä»¥åŠå˜Ÿå˜Ÿè„¸çš„ç”Ÿæˆå°±ä¼šè½»æ¾è®¸å¤šã€‚


<p align="center">
<img src="https://paddlehub.bj.bcebos.com/resources/face_landmark.jpg"  hspace='5' width=500/> <br />
</p>


```python
import cv2
import paddlehub as hub
import matplotlib.pyplot as plt 
import matplotlib.image as mpimg
import numpy as np
import math
from PIL import Image
src_img = cv2.imread('example.jpg')

# åŠ è½½æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹
module = hub.Module(name="face_landmark_localization")
result = module.keypoint_detection(images=[src_img])

tmp_img = src_img.copy()
for index, point in enumerate(result[0]['data'][0]):
	# cv2.putText(img, str(index), (int(point[0]), int(point[1])), cv2.FONT_HERSHEY_COMPLEX, 3, (0,0,255), -1)
	cv2.circle(tmp_img, (int(point[0]), int(point[1])), 2, (0, 0, 255), -1)

res_img_path = 'face_landmark.jpg'
cv2.imwrite(res_img_path, tmp_img)

img = mpimg.imread(res_img_path) 
# å±•ç¤ºé¢„æµ‹68ä¸ªå…³é”®ç‚¹ç»“æœ(è‹¥æœªæ˜¾ç¤ºå…³é”®ç‚¹å¯è§†åŒ–ç»“æœè¯·å†æ¬¡è¿è¡Œæ­¤cell)
plt.figure(figsize=(10,10))
plt.imshow(img) 
plt.axis('off') 
plt.show()
```

    [2021-11-30 14:27:46,626] [ WARNING] - The _initialize method in HubModule will soon be deprecated, you can use the __init__() to handle the initialization of the object
    [2021-11-30 14:27:46,743] [ WARNING] - The _initialize method in HubModule will soon be deprecated, you can use the __init__() to handle the initialization of the object
    [37m---    Fused 0 subgraphs into layer_norm op.[0m
    [37m---    Fused 0 subgraphs into layer_norm op.[0m




![png](output_5_1.png)
    


## ä¸‰ã€åˆ»ç”»èœ¡ç¬”çœ‰

åœ¨ä¸Šä¸€æ­¥ä¸­æˆ‘ä»¬å¾—åˆ°äº†äººè„¸68ä¸ªå…³é”®ç‚¹åæ ‡ï¼Œå…¶ä¸­18-22ï¼Œ23-27ä¸ºçœ‰æ¯›çš„åæ ‡å€¼ã€‚æƒ³å¾—åˆ°èœ¡ç¬”å°æ–°è¿™ç…§ç‰‡çš„ç²—ç²—çœ‰ï¼Œç®€å•æ¥è®²åªéœ€å°†çœ‰æ¯›çš„åæ ‡ç‚¹è¿æˆçº¿ï¼Œæ§åˆ¶é€‚å½“çš„å®½åº¦å³å¯ã€‚

è¿™é‡Œå¯ä»¥ä½¿ç”¨opencvçš„line()å‡½æ•°è½»æ¾å®ç°ã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/4e19215d114b45c2974c9159b1a468f237e4e36bae9d487e92c275b72fd08aea)




```python
def thick_eyebrows(image, face_landmark, width):
	for i in range(18-1, 22-1):
		cv2.line(image, face_landmark[i], face_landmark[i+1], (0, 0, 0), width)
	for i in range(23-1, 27-1):
		cv2.line(image, face_landmark[i], face_landmark[i+1], (0, 0, 0), width)
	return image

# æå–å‡ºäººè„¸å…³é”®ç‚¹åæ ‡
face_landmark = np.array(result[0]['data'][0], dtype='int')
# ç”Ÿæˆèœ¡ç¬”å°æ–°ç‰ˆçœ‰æ¯›
width = 8
src_img = thick_eyebrows(src_img, face_landmark, width)
cv2.imwrite('thick_eyebrows.jpg', src_img)


img = mpimg.imread('thick_eyebrows.jpg') 
# å±•ç¤ºèœ¡ç¬”çœ‰
plt.figure(figsize=(10,10))
plt.imshow(img) 
plt.axis('off') 
plt.show()
```


â€‹    
![png](output_7_0.png)
â€‹    


## å››ã€æ‰“è‚¿è„¸å……å°æ–°

åœ¨è¿™é‡Œï¼Œä½¿ç”¨äº†[å›¾åƒå±€éƒ¨å¹³ç§»ç®—æ³•](https://blog.csdn.net/grafx/article/details/70232797?locationNum=11&fps=1)ã€‚æ€è·¯æ˜¯ï¼šç”±å˜å½¢å‰åæ ‡ï¼Œæ ¹æ®å˜å½¢æ˜ å°„å…³ç³»ï¼Œå¾—åˆ°å˜å½¢ååæ ‡ã€‚è¿™å…¶ä¸­å˜å½¢æ˜ å°„å…³ç³»æ˜¯æœ€å…³é”®çš„ï¼Œä¸åŒçš„æ˜ å°„å…³ç³»ï¼Œå°†å¾—åˆ°ä¸åŒçš„å˜å½¢æ•ˆæœã€‚å¹³ç§»ã€ç¼©æ”¾ã€æ—‹è½¬ï¼Œå¯¹åº”çš„æ˜¯ä¸åŒçš„æ˜ å°„å…³ç³»ï¼Œå³ä¸åŒçš„å˜æ¢å…¬å¼ã€‚å½“ç„¶å®é™…åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œç”¨çš„æ˜¯é€†å˜æ¢ï¼Œå³ç”±å˜å½¢ååæ ‡ï¼Œæ ¹æ®é€†å˜æ¢å…¬å¼åç®—å˜å½¢å‰åæ ‡ï¼Œç„¶åæ’å€¼å¾—åˆ°è¯¥åæ ‡rgbåƒç´ å€¼ï¼Œå°†è¯¥rgbå€¼ä½œä¸ºå˜å½¢ååæ ‡å¯¹åº”çš„åƒç´ å€¼ã€‚è¿™æ ·æ‰èƒ½ä¿è¯å˜å½¢åçš„å›¾åƒæ˜¯è¿ç»­ã€å®Œæ•´çš„ã€‚


```python
# è¿›è¡Œèƒ–è„¸æ“ä½œ
def fat_face(image, face_landmark):
    end_point = face_landmark[30]

    # èƒ–å·¦è„¸ï¼Œ3å·ç‚¹åˆ°5å·ç‚¹çš„è·ç¦»ä½œä¸ºä¸€æ¬¡èƒ–è„¸è·ç¦»
    dist_left = np.linalg.norm(face_landmark[3] - face_landmark[5])
    image = local_traslation_warp(image, face_landmark[3], end_point, dist_left)

    # èƒ–å³è„¸ï¼Œ13å·ç‚¹åˆ°15å·ç‚¹çš„è·ç¦»ä½œä¸ºä¸€æ¬¡èƒ–è„¸è·ç¦»
    dist_right = np.linalg.norm(face_landmark[13] - face_landmark[15])
    image = local_traslation_warp(image, face_landmark[13], end_point, dist_right)
    return image
```


```python
# å±€éƒ¨å¹³ç§»ç®—æ³•
def local_traslation_warp(image, start_point, end_point, radius):
	radius_square = math.pow(radius, 2)
	image_cp = image.copy()

	dist_se = math.pow(np.linalg.norm(end_point - start_point), 2)
	height, width, channel = image.shape
	for i in range(width):
		for j in range(height):
			# è®¡ç®—è¯¥ç‚¹æ˜¯å¦åœ¨å½¢å˜åœ†çš„èŒƒå›´ä¹‹å†…
			# ä¼˜åŒ–ï¼Œç¬¬ä¸€æ­¥ï¼Œç›´æ¥åˆ¤æ–­æ˜¯ä¼šåœ¨ï¼ˆstart_point[0], start_point[1])çš„çŸ©é˜µæ¡†ä¸­
			if math.fabs(i - start_point[0]) > radius and math.fabs(j - start_point[1]) > radius:
				continue

			distance = (i - start_point[0]) * (i - start_point[0]) + (j - start_point[1]) * (j - start_point[1])

			if distance < radius_square:
				# è®¡ç®—å‡ºï¼ˆi,jï¼‰åæ ‡çš„åŸåæ ‡
				# è®¡ç®—å…¬å¼ä¸­å³è¾¹å¹³æ–¹å·é‡Œçš„éƒ¨åˆ†
				ratio = (radius_square - distance) / (radius_square - distance + dist_se)
				ratio = ratio * ratio

				# æ˜ å°„åŸä½ç½®
				new_x = i + ratio * (end_point[0] - start_point[0])
				new_y = j + ratio * (end_point[1] - start_point[1])

				new_x = new_x if new_x >= 0 else 0
				new_x = new_x if new_x < height - 1 else height - 2
				new_y = new_y if new_y >= 0 else 0
				new_y = new_y if new_y < width - 1 else width - 2

				# æ ¹æ®åŒçº¿æ€§æ’å€¼æ³•å¾—åˆ°new_x, new_yçš„å€¼
				image_cp[j, i] = bilinear_insert(image, new_x, new_y)

	return image_cp


# åŒçº¿æ€§æ’å€¼æ³•
def bilinear_insert(image, new_x, new_y):
	w, h, c = image.shape
	if c == 3:
		x1 = int(new_x)
		x2 = x1 + 1
		y1 = int(new_y)
		y2 = y1 + 1

		part1 = image[y1, x1].astype(np.float) * (float(x2) - new_x) * (float(y2) - new_y)
		part2 = image[y1, x2].astype(np.float) * (new_x - float(x1)) * (float(y2) - new_y)
		part3 = image[y2, x1].astype(np.float) * (float(x2) - new_x) * (new_y - float(y1))
		part4 = image[y2, x2].astype(np.float) * (new_x - float(x1)) * (new_y - float(y1))

		insertvalue = part1 + part2 + part3 + part4

		return insertvalue.astype(np.int8)
```


```python
# è¿›è¡Œèƒ–è„¸æ“ä½œ
fat_nums = 3
for i in range(1, fat_nums):
	src_img = fat_face(src_img, face_landmark)

cv2.imwrite('res.jpg', src_img)
img = mpimg.imread('res.jpg') 
# å±•ç¤ºèœ¡ç¬”çœ‰+å˜Ÿå˜Ÿå˜´
plt.figure(figsize=(10,10))
plt.imshow(img) 
plt.axis('off') 
plt.show()
```


â€‹    
![png](output_11_0.png)
â€‹    


## äº”ã€ä¸€é”®æ‰§è¡Œ~(ä¸Šè¿°ä¸ºè¿‡ç¨‹å±•ç¤ºéƒ¨åˆ†ï¼Œå¯åœ¨æ­¤å¤„ä¸€é”®å¯»æ‰¾è¿œæ–¹è¡¨å¼Ÿå“¦)

run.pyä¸­å¼•å‡ºäº†å››ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯ï¼š

```
img_path è¾“å…¥å›¾ç‰‡è·¯å¾„
width çœ‰æ¯›å®½åº¦
res_img_path è¾“å‡ºå›¾ç‰‡è·¯å¾„
fat_nums å˜Ÿå˜Ÿè„¸ç³»æ•°

```
ä¾ç…§å‚æ•°æè¿°è¿›è¡Œç›¸åº”çš„ä¿®æ”¹å³å¯ï¼Œé¡ºåˆ©è¿è¡Œä¸‹æ–¹å‘½ä»¤å¹¶æ‰“å°å‡ºdoneä¹‹åï¼Œå¯åœ¨å·¦ä¾§(**/home/aistudio**)ç›®å½•ä¸‹æ‰¾åˆ°è¾“å‡ºå›¾ç‰‡(**é»˜è®¤:res.jpg**)


```python
!python run.py --img_path example.jpg --width 8 --res_img_path res.jpg --fat_nums 3
```

## æ¥ç§ç§æ•ˆæœå§ï¼ï¼ˆå—å®³è€…ä¸å®šæœŸæ›´æ–°~ï¼‰

![](https://ai-studio-static-online.cdn.bcebos.com/f62867505ce848fa8d31778a2b2f608439772584d7a341b68129c1f88fe848e4)

![](https://ai-studio-static-online.cdn.bcebos.com/84b18b8de9704c4c8c938f79f093dd769824991591ee46779f133c1ecb1e32c6)

![](https://ai-studio-static-online.cdn.bcebos.com/79d680c949184b0ea53740ab42dc3e6090d601a23b184b3d897599bace30ed15)

![](https://ai-studio-static-online.cdn.bcebos.com/79ccf037dfd048f1a9df06c18bf68476b8939d7e037b46009dc94b1043a88dc1)

(å¦ˆå¦ˆï¼Œå¦ˆå¦ˆï¼Œæˆ‘è·ŸPPDEå¤§ä½¬ä»¬åŒæ¡†äº†å“ˆå“ˆå“ˆå“ˆ)

## æ€»ç»“

ä»…éœ€ç®€ç®€å•å•çš„å››æ­¥å°±èƒ½å¯»æ‰¾åˆ°èœ¡ç¬”å°æ–°çš„è¿œæ–¹è¡¨å¼Ÿï¼Œç§ƒç„¶åˆå¤šäº†ä¸€å †å…„å¼Ÿå‘¢ã€‚

è¿™ä¸ªæ–¹æ¡ˆçš„åŸç†æ˜¯é¦–å…ˆå¯¹å›¾ç‰‡è¿›è¡Œ[äººè„¸å…³é”®ç‚¹æ£€æµ‹](https://www.paddlepaddle.org.cn/hubdetail?name=face_landmark_localization&en_category=KeyPointDetection)ï¼Œæœ‰äº†äººè„¸68ä¸ªå…³é”®ç‚¹åæ ‡åå°±å¥½åŠäº†ã€‚æµ“çœ‰çš„ç”Ÿæˆä»…éœ€ä½¿ç”¨opencvåœ¨çœ‰æ¯›å¤„è¿›è¡Œç”»çº¿æ“ä½œï¼Œè€Œç¬¬å››æ­¥çš„â€œç‰™é¾ˆå‘ç‚ç”Ÿæˆå™¨â€åˆ™æ˜¯åˆ©ç”¨[å±€éƒ¨å¹³ç§»ç®—æ³•](http://www.gson.org/thesis/warping-thesis.pdf)å®Œæˆçš„ã€‚

é‚£æœ€åçš„æœ€åï¼Œï¼Œï¼Œä¸å®šæœŸæŠ½å–å¹¸è¿çš„å°ä¼™ä¼´ï¼Œæˆ‘æ¥å¸®ä½ æ‰¾ä½ çš„è¿œæ–¹å…„å¼Ÿå“¦(æ‰‹åŠ¨ç‹—å¤´)

## ä¸ªäººç®€ä»‹

> ä½œè€…ï¼š AP-Kai 

> å­¦æ ¡ï¼š æ²ˆé˜³å·¥ä¸šå¤§å­¦ å¤§äºŒåœ¨è¯»

> AI Studio: [https://aistudio.baidu.com/aistudio/personalcenter/thirdview/675310](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/675310)

> GitHub: [https://github.com/AP-Kai/AP-Kai](https://github.com/AP-Kai/AP-Kai)



è¯·ç‚¹å‡»[æ­¤å¤„](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)æŸ¥çœ‹æœ¬ç¯å¢ƒåŸºæœ¬ç”¨æ³•.  <br>
Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. 